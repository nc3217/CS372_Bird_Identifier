# -*- coding: utf-8 -*-
"""EfficientNet_Bird_Identifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Tt01Wsg79M6KMKfMOtRvQRg4Y42hGGt0

## **Loading Dataset**
"""

from google.colab import files
files.upload()   # upload kaggle.json here

import kagglehub
path = kagglehub.dataset_download("sharansmenon/inatbirds100k")
print("Dataset path:", path)

import os
print(os.listdir(path))

# Figure out where training dataset path is

import os

for root, dirs, files in os.walk(path):
    print("ROOT:", root)
    print("DIRS:", dirs)
    print("FILES:", files[:5])
    print("--------")

import os
import pandas as pd

data = []

root_path = os.path.join(path, "birds_train_small")

for species in os.listdir(root_path):
    species_path = os.path.join(root_path, species)

    if not os.path.isdir(species_path):
        continue

    for img in os.listdir(species_path):
        if img.lower().endswith((".jpg", ".jpeg", ".png")):
            img_path = os.path.join(species_path, img)
            data.append([img_path, species])

df = pd.DataFrame(data, columns=["image_path", "label"])

len(df)

"""## **Splitting Dataset**


"""

from sklearn.model_selection import train_test_split


train_df, test_df = train_test_split(df, test_size=0.20, stratify=df['label'], random_state=42)

train_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['label'], random_state=42)

print(len(train_df), len(val_df), len(test_df))

"""## **Random Baseline Model Based on Probabilities in Dataset**"""

import numpy as np
import pandas as pd

def class_prior_random_baseline(train_df, test_df, label_col="label", seed=None):

    if seed is not None:
        np.random.seed(seed)

    # compute class frequencies in the training data
    class_counts = train_df[label_col].value_counts().sort_index()
    class_probs = class_counts / class_counts.sum()


    y_true = test_df[label_col].values

    # predictions
    y_pred = np.random.choice(
        a=class_counts.index.values,   # class IDs
        size=len(test_df),
        p=class_probs.values
    )

    # accuracy
    accuracy = (y_pred == y_true).mean()

    return accuracy

baseline_acc = class_prior_random_baseline(train_df, test_df, seed=42)
print("Class-prior random baseline accuracy:", baseline_acc)

"""## **Loading Pre-Trained CLIP Model and Generating Image Embeddings**

Used ChatGPT to change embedding code to loop through batches of data
"""

import torch
from transformers import CLIPProcessor, CLIPModel
from PIL import Image
from pathlib import Path
import numpy as np
from tqdm import tqdm

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

SAVE_PATH = "/content/drive/MyDrive/bird_clip_embeddings.npy"
SAVE_LABELS = "/content/drive/MyDrive/bird_clip_labels.npy"

# load CLIP model
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
clip_model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32", weights_only=False).to(device)
clip_processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")


image_paths = train_df['image_path'].tolist()
labels = train_df['label'].values

BATCH_SIZE = 64
total_embeddings = []

# computing and saving embeddings
for i in tqdm(range(0, len(image_paths), BATCH_SIZE)):
    batch_paths = image_paths[i:i+BATCH_SIZE]
    batch_images = [Image.open(Path(p)) for p in batch_paths]

    inputs = clip_processor(images=batch_images, return_tensors="pt").to(device)

    with torch.no_grad():
        batch_emb = clip_model.get_image_features(**inputs)

    batch_emb = batch_emb / batch_emb.norm(dim=-1, keepdim=True)
    total_embeddings.append(batch_emb.cpu().numpy())

image_embeddings = np.concatenate(total_embeddings, axis=0)

np.save(SAVE_PATH, image_embeddings)
np.save(SAVE_LABELS, labels)

print("Saved embeddings to:", SAVE_PATH)
print("Saved labels to:", SAVE_LABELS)
print("Embedding shape:", image_embeddings.shape)

"""## **Generating Logistic Regression Baseline**"""

from pathlib import Path
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import joblib, json

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# paths for embeddings and labels
EMB_PATH = "/content/drive/MyDrive/bird_clip_embeddings.npy"
LABEL_PATH = "/content/drive/MyDrive/bird_clip_labels.npy"

X = np.load(EMB_PATH)
y_raw = np.load(LABEL_PATH, allow_pickle=True)

print("Loaded embeddings:", X.shape)
print("Loaded labels:", y_raw.shape)

# convert labels to integers
if y_raw.dtype.kind in {'U', 'S', 'O'}:
    unique = sorted(list(set(y_raw.tolist())))
    label2idx = {lab: i for i, lab in enumerate(unique)}
    idx2label = {i: lab for lab, i in label2idx.items()}
    y = np.array([label2idx[s] for s in y_raw], dtype=np.int32)
else:
    y = y_raw.astype(np.int32)
    idx2label = {i: str(i) for i in range(int(y.max()) + 1)}

print("Num classes:", len(idx2label))

# normalize embeddings
X = X / np.linalg.norm(X, axis=1, keepdims=True)

# split training and validation
X_tr, X_val, y_tr, y_val = train_test_split(
    X, y, test_size=0.15, stratify=y, random_state=42
)

print("Training logistic regression on", X_tr.shape[0], "samples")


clf = LogisticRegression(
    max_iter=300,
    solver='lbfgs',
    C=1.0,
    n_jobs=-1,
    multi_class='auto'
)

clf.fit(X_tr, y_tr)

y_pred = clf.predict(X_val)
print("Validation accuracy:", accuracy_score(y_val, y_pred))

print(classification_report(
    y_val, y_pred,
    target_names=[idx2label[i] for i in sorted(idx2label)]
))

# save model and label map
OUTDIR = Path("/content/drive/MyDrive/bird_models")
OUTDIR.mkdir(exist_ok=True)

joblib.dump(clf, OUTDIR / "logistic_baseline.joblib")
json.dump(idx2label, open(OUTDIR / "label_map.json", "w"))

print("Saved model to:", OUTDIR / "logistic_baseline.joblib")
print("Saved label map to:", OUTDIR / "label_map.json")

"""## **EfficientNet**"""

!pip install -q timm albumentations==1.3.0

import os
import math
from pathlib import Path
from tqdm.auto import tqdm

import numpy as np
import pandas as pd
from PIL import Image

import torch
from torch import nn
from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler
import torch.nn.functional as F
from torch.optim import AdamW
from sklearn.metrics import accuracy_score, f1_score, classification_report

import timm
import albumentations as A
from albumentations.pytorch import ToTensorV2

# hyperparameters
MODEL_NAME = "tf_efficientnet_b3"
IMG_SIZE = 300
BATCH_SIZE = 32
EPOCHS = 12
LR = 1e-4
WEIGHT_DECAY = 1e-2
OUTPUT_DIR = "/content/drive/MyDrive/bird_models"
USE_WEIGHTED_SAMPLER = True
PRETRAINED = True
NUM_WORKERS = 4
PIN_MEMORY = True

os.makedirs(OUTPUT_DIR, exist_ok=True)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Device:", device)

# Convert labels to a contiguous integer range
all_labels = pd.concat([train_df['label'], test_df['label'], val_df['label']]).unique()
all_labels = sorted(list(all_labels))
label2idx = {lab: i for i, lab in enumerate(all_labels)}
idx2label = {i:lab for lab,i in label2idx.items()}
n_classes = len(label2idx)
print("Num classes:", n_classes)

train_df = train_df.copy()
test_df  = test_df.copy()
val_df = val_df.copy()
train_df['label_idx'] = train_df['label'].map(label2idx)
test_df['label_idx']  = test_df['label'].map(label2idx)
val_df['label_idx'] = val_df['label'].map(label2idx)

# transform images in dataset
def get_transforms(img_size=IMG_SIZE, train=True):
    if train:
        return A.Compose([
            A.RandomResizedCrop(img_size, img_size, scale=(0.6,1.0), p=1.0),
            A.HorizontalFlip(p=0.5),
            A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.15, rotate_limit=20, p=0.3),
            A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.02, p=0.5),
            A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),
            ToTensorV2()
        ])
    else:
        return A.Compose([
            A.Resize(img_size, img_size),
            A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),
            ToTensorV2()
        ])

class CSVImageDataset(Dataset):
    def __init__(self, df, img_col='image_path', label_col='label_idx', transform=None):
        self.df = df.reset_index(drop=True)
        self.img_col = img_col
        self.label_col = label_col
        self.transform = transform
    def __len__(self):
        return len(self.df)
    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        img_path = row[self.img_col]
        # PIL open and convert
        img = Image.open(img_path).convert('RGB')
        img = np.array(img)
        if self.transform is not None:
            img = self.transform(image=img)['image']
        label = int(row[self.label_col])
        return img, label

train_ds = CSVImageDataset(train_df, transform=get_transforms(IMG_SIZE, train=True))
val_ds   = CSVImageDataset(val_df,  transform=get_transforms(IMG_SIZE, train=False))

# sampler to help mitigate any class imbalance
train_sampler = None
if USE_WEIGHTED_SAMPLER:
    counts = train_df['label_idx'].value_counts().sort_index().values
    class_weights = 1.0 / (counts + 1e-12)
    sample_weights = train_df['label_idx'].map(lambda x: class_weights[x]).values
    train_sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)
    shuffle = False
else:
    shuffle = True

# data loaders
train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=train_sampler, shuffle=shuffle if train_sampler is None else False,
                          num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)
val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)

print("Train samples:", len(train_ds), "Val samples:", len(val_ds))

# create model
model = timm.create_model(MODEL_NAME, pretrained=PRETRAINED, num_classes=n_classes)
model.to(device)


criterion = nn.CrossEntropyLoss()
optimizer = AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)
scaler = torch.amp.GradScaler()

# training function
def train_one_epoch(model, loader, optimizer, scaler, device, criterion):
    model.train()
    running_loss = 0.0
    y_true, y_pred = [], []
    pbar = tqdm(loader, desc="train", leave=False)
    for imgs, labels in pbar:
        imgs = imgs.to(device, non_blocking=True)
        labels = labels.to(device, non_blocking=True)
        optimizer.zero_grad()
        with torch.amp.autocast(device_type=device.type, enabled=torch.cuda.is_available()):
            logits = model(imgs)
            loss = criterion(logits, labels)
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
        running_loss += loss.item() * imgs.size(0)
        preds = logits.argmax(dim=1).detach().cpu().numpy()
        y_pred.extend(preds.tolist())
        y_true.extend(labels.detach().cpu().numpy().tolist())
    avg_loss = running_loss / len(loader.dataset)
    acc = accuracy_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred, average='macro')
    return avg_loss, acc, f1

# validation function
@torch.no_grad()
def validate(model, loader, device, criterion):
    model.eval()
    running_loss = 0.0
    y_true, y_pred = [], []
    pbar = tqdm(loader, desc="val", leave=False)
    for imgs, labels in pbar:
        imgs = imgs.to(device, non_blocking=True)
        labels = labels.to(device, non_blocking=True)
        with torch.amp.autocast(device_type=device.type, enabled=torch.cuda.is_available()):
            logits = model(imgs)
            loss = criterion(logits, labels)
        running_loss += loss.item() * imgs.size(0)
        preds = logits.argmax(dim=1).detach().cpu().numpy()
        y_pred.extend(preds.tolist())
        y_true.extend(labels.detach().cpu().numpy().tolist())
    avg_loss = running_loss / len(loader.dataset)
    acc = accuracy_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred, average='macro')
    return avg_loss, acc, f1, y_true, y_pred

# training loop
best_val_f1 = -1.0
for epoch in range(1, EPOCHS+1):
    print(f"\nEpoch {epoch}/{EPOCHS}")
    train_loss, train_acc, train_f1 = train_one_epoch(model, train_loader, optimizer, scaler, device, criterion)
    val_loss, val_acc, val_f1, y_true, y_pred = validate(model, val_loader, device, criterion)
    scheduler.step()
    print(f"Train loss {train_loss:.4f} acc {train_acc:.4f} f1 {train_f1:.4f}")
    print(f"Val   loss {val_loss:.4f} acc {val_acc:.4f} f1 {val_f1:.4f}")
    # Save checkpoint
    ckpt = {
        "epoch": epoch,
        "model_state": model.state_dict(),
        "optimizer_state": optimizer.state_dict(),
        "val_f1": val_f1
    }
    torch.save(ckpt, os.path.join(OUTPUT_DIR, f"ckpt_epoch{epoch}.pth"))
    if val_f1 > best_val_f1:
        best_val_f1 = val_f1
        torch.save(ckpt, os.path.join(OUTPUT_DIR, "best.pth"))
        print("Saved best model.")
    if epoch % 3 == 0:
        print("Sample classification report (first 30 classes):")
        try:
            print(classification_report(y_true, y_pred, target_names=[idx2label[i] for i in range(min(n_classes,30))], zero_division=0))
        except Exception:
            pass
    if train_acc >= 0.61:
      break
print("Training finished. Best val F1:", best_val_f1)

# Computing inference timing, metric, and error analysis parameters

import json, time, os
from pathlib import Path
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image

import torch
from torch.utils.data import Dataset, DataLoader
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score


DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
OUT = Path(OUTPUT_DIR)
OUT.mkdir(parents=True, exist_ok=True)

WARMUP_ITERS = 5
MISCLASS_PER_CLASS = 5
MIN_SUPPORT = 10

print("Using device:", DEVICE)
print("Saving outputs to:", OUT)


if "label_idx" not in test_df.columns:
    test_df = test_df.copy()
    test_df["label_idx"] = test_df["label"].map(label2idx)


test_tf = get_transforms(img_size=IMG_SIZE, train=False)

class CSVImageDataset(Dataset):
    def __init__(self, df, img_col="image_path", label_col="label_idx", transform=None):
        self.df = df.reset_index(drop=True)
        self.img_col = img_col
        self.label_col = label_col
        self.transform = transform

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        img = Image.open(row[self.img_col]).convert("RGB")
        img = np.array(img)
        if self.transform:
            img = self.transform(image=img)["image"]
        label = int(row[self.label_col])
        return img, label, row[self.img_col]

test_ds = CSVImageDataset(test_df, transform=test_tf)
test_loader = DataLoader(test_ds, batch_size=64, shuffle=False,
                         num_workers=4, pin_memory=True)

print("Test samples:", len(test_ds))

# ensure model is loaded
if "model" not in globals():
    print("No model in memory: loading best.pth...")
    best_path = OUT / "best.pth"
    ckpt = torch.load(best_path, map_location=DEVICE)
    model = timm.create_model(MODEL_NAME, pretrained=False, num_classes=len(idx2label))
    model.load_state_dict(ckpt.get("model_state", ckpt), strict=False)
    model.to(DEVICE)

model.eval()

# run inference
print("\nRunning inference over test set...")
ys, preds, probs, paths = [], [], [], []

with torch.no_grad():
    for imgs, labels, img_paths in test_loader:
        imgs = imgs.to(DEVICE)
        logits = model(imgs)
        p = torch.softmax(logits, dim=1).cpu().numpy()
        pr = logits.argmax(dim=1).cpu().numpy()

        probs.append(p)
        preds.append(pr)
        ys.append(labels.numpy())
        paths.extend(img_paths)

probs = np.concatenate(probs)
y_pred = np.concatenate(preds)
y_true = np.concatenate(ys)


print("\nMeasuring inference timing...")
if DEVICE.type == "cuda":
    with torch.no_grad():
        it = 0
        for imgs, _, _ in test_loader:
            imgs = imgs.to(DEVICE)
            _ = model(imgs)
            it += 1
            if it >= WARMUP_ITERS:
                break

batch_times = []
total_images = 0
start_all = time.perf_counter()

with torch.no_grad():
    for imgs, _, _ in test_loader:
        imgs = imgs.to(DEVICE)
        if DEVICE.type == "cuda":
            torch.cuda.synchronize()
        t_start = time.perf_counter()
        _ = model(imgs)
        if DEVICE.type == "cuda":
            torch.cuda.synchronize()
        t_end = time.perf_counter()

        batch_times.append((t_end - t_start, imgs.shape[0]))
        total_images += imgs.shape[0]

end_all = time.perf_counter()
total_time = end_all - start_all
throughput = total_images / total_time

latencies = np.concatenate([np.repeat(bt / bs, bs) for bt, bs in batch_times])
lat_mean = latencies.mean()
lat_median = np.median(latencies)
lat_p95 = np.percentile(latencies, 95)

print("\nINFERENCE TIMING SUMMARY:")
print(f"  Total images: {total_images}, Time: {total_time:.3f}s")
print(f"  Throughput: {throughput:.2f} img/s")
print(f"  Mean latency: {lat_mean*1000:.2f} ms")
print(f"  Median latency: {lat_median*1000:.2f} ms")
print(f"  p95 latency: {lat_p95*1000:.2f} ms")

# compute and output metrics
acc_top1 = accuracy_score(y_true, y_pred)
prec_macro = precision_score(y_true, y_pred, average="macro", zero_division=0)
rec_macro = recall_score(y_true, y_pred, average="macro", zero_division=0)
f1_macro = f1_score(y_true, y_pred, average="macro", zero_division=0)

top5_acc = None
if probs.shape[1] >= 5:
    top5_preds = np.argsort(probs, axis=1)[:, -5:]
    top5_acc = np.mean([1 if y_true[i] in top5_preds[i] else 0 for i in range(len(y_true))])

print("\nMETRICS (TEST SET):")
print(f"  Top-1 Accuracy : {acc_top1:.4f}")
print(f"  Macro F1       : {f1_macro:.4f}")
print(f"  Precision      : {prec_macro:.4f}")
print(f"  Recall         : {rec_macro:.4f}")
print(f"  Top-5 Accuracy : {top5_acc:.4f}")


summary = {
    "device": str(DEVICE),
    "total_images": int(total_images),
    "total_time_s": float(total_time),
    "throughput_img_per_s": float(throughput),
    "lat_mean_s": float(lat_mean),
    "lat_median_s": float(lat_median),
    "lat_p95_s": float(lat_p95),
    "top1_acc": float(acc_top1),
    "macro_f1": float(f1_macro),
    "precision_macro": float(prec_macro),
    "recall_macro": float(rec_macro),
    "top5_acc": float(top5_acc),
}
Path(OUT/"inference_summary.json").write_text(json.dumps(summary, indent=2))

print("Saved inference_summary.json")

# per-class f1
print("\nComputing per-class F1...")
classes = sorted(idx2label.keys())
per_class = []

for c in classes:
    support = int((y_true == c).sum())
    if support < MIN_SUPPORT:
        continue
    f1c = f1_score((y_true == c).astype(int),
                   (y_pred == c).astype(int),
                   average="binary",
                   zero_division=0)
    per_class.append((c, idx2label[c], f1c, support))

pc_df = pd.DataFrame(per_class, columns=["idx", "label", "f1", "support"])
pc_df = pc_df.sort_values("f1").reset_index(drop=True)
pc_df.to_csv(OUT/"per_class_f1.csv", index=False)
display(pc_df.head(30))

# worst-class misclassifications
print("\nVisualizing misclassified examples for worst classes...")
worst = pc_df.head(5)

plt.figure(figsize=(18, 12))
plot_idx = 1
for _, row in worst.iterrows():
    cls_idx = int(row["idx"])
    mis_idx = np.where((y_true == cls_idx) & (y_pred != cls_idx))[0]
    sel = mis_idx[:MISCLASS_PER_CLASS]

    for mid in sel:
        img_path = test_df.iloc[mid]["image_path"]
        true_lbl = idx2label[int(y_true[mid])]
        pred_lbl = idx2label[int(y_pred[mid])]
        prob_pred = float(probs[mid, int(y_pred[mid])])
        prob_true = float(probs[mid, int(y_true[mid])])

        try:
            im = Image.open(img_path).convert("RGB").resize((256, 256))
        except:
            continue

        ax = plt.subplot(len(worst), MISCLASS_PER_CLASS, plot_idx)
        ax.imshow(im); ax.axis("off")
        ax.set_title(f"T:{true_lbl[:30]}\nP:{pred_lbl[:30]}\nP:{prob_pred:.2f} T:{prob_true:.2f}", fontsize=8)
        plot_idx += 1

plt.tight_layout()
plt.savefig(OUT/"misclassified_examples.png", dpi=150)
plt.show()

# three examples of misclassifications in more detail
print("\nGenerating 3 detailed misclassifications...\n")

mis_idx_all = np.where(y_true != y_pred)[0]
if len(mis_idx_all) == 0:
    print("No misclassifications found.")
else:
    chosen = np.random.choice(mis_idx_all, size=min(3, len(mis_idx_all)), replace=False)
    fig = plt.figure(figsize=(14, 6))

    for i, mid in enumerate(chosen, start=1):
        img_path = test_df.iloc[mid]["image_path"]
        im = Image.open(img_path).convert("RGB").resize((300, 300))

        true_lbl = idx2label[int(y_true[mid])]
        pred_lbl = idx2label[int(y_pred[mid])]

        top5_idx = probs[mid].argsort()[-5:][::-1]
        top5_labels = [idx2label[k] for k in top5_idx]
        top5_scores = [float(probs[mid][k]) for k in top5_idx]

        ax = fig.add_subplot(1, 3, i)
        ax.imshow(im); ax.axis("off")
        ax.set_title(f"Example {i}", fontsize=12)

        print(f"EXAMPLE {i}")
        print(f"Image: {img_path}")
        print(f"TRUE LABEL:      {true_lbl}")
        print(f"PREDICTED LABEL: {pred_lbl}")
        print("Top-5 Predictions:")
        for lbl, score in zip(top5_labels, top5_scores):
            print(f"   {lbl:45s} {score:.4f}")
        print("\n")

    plt.tight_layout()
    plt.savefig(OUT/"example_misclassifications.png", dpi=150)
    plt.show()

print("\nDone! Analysis saved to:", OUT)

# run this to test out the model!
import torch
import timm
import numpy as np
from PIL import Image
from pathlib import Path

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
MODEL_NAME = "tf_efficientnet_b3"
IMG_SIZE = 300
OUTPUT_DIR = "/content/drive/MyDrive/bird_models"


import json
label_map_path = Path(OUTPUT_DIR) / "label_map.json"
idx2label = {int(k): v for k, v in json.loads(label_map_path.read_text()).items()}
label2idx = {v: k for k, v in idx2label.items()}

n_classes = len(idx2label)

print("Loaded label maps:", n_classes, "classes")



# transforms
import albumentations as A
from albumentations.pytorch import ToTensorV2

def get_transforms(img_size=IMG_SIZE):
    return A.Compose([
        A.Resize(img_size, img_size),
        A.Normalize(mean=(0.485,0.456,0.406),
                    std=(0.229,0.224,0.225)),
        ToTensorV2()
    ])

infer_tf = get_transforms()


# load model
best_path = Path(OUTPUT_DIR) / "best.pth"

print("Loading model from:", best_path)

ckpt = torch.load(best_path, map_location=DEVICE)
model = timm.create_model(MODEL_NAME, pretrained=False, num_classes=n_classes)

state = ckpt.get("model_state", ckpt)
model.load_state_dict(state, strict=False)

model.to(DEVICE)
model.eval()

print("Model loaded successfully.")


# prediction function
def predict_image(img_path, topk=5):
    """
    Runs inference on a single image path and returns top-k predictions.
    """

    # Load image
    img = Image.open(img_path).convert("RGB")
    arr = np.array(img)

    # Apply transforms
    tensor = infer_tf(image=arr)["image"].unsqueeze(0).to(DEVICE)

    # Forward pass
    with torch.no_grad():
        logits = model(tensor)
        probs = torch.softmax(logits, dim=1).cpu().numpy()[0]

    # Top-k
    idxs = probs.argsort()[::-1][:topk]
    results = [(idx2label[int(i)], float(probs[i])) for i in idxs]

    return results

# show the prediction
def show_prediction(img_path, topk=5):
    """
    Prints results cleanly and displays the image.
    """
    from IPython.display import display

    img = Image.open(img_path)
    display(img)

    preds = predict_image(img_path, topk=topk)

    print("\nðŸ”Ž Top Predictions:")
    for rank, (label, score) in enumerate(preds, start=1):
        print(f"{rank}. {label} â€” {score:.4f}")


# Put your own filename here:
test_img = "/content/sample_bird.jpg"

print("\nRunning model on:", test_img)
show_prediction(test_img, topk=5)